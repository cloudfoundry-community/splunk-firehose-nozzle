{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"General information","text":""},{"location":"#splunk-nozzle","title":"Splunk Nozzle","text":"<p>Cloud Foundry Firehose-to-Splunk Nozzle</p>"},{"location":"#vmware-tanzu-application-service-version","title":"VMware Tanzu Application Service version","text":"<p>Splunk Firehose Nozzle has been tested on v3.0.0 and v4.0.0 of Tanzu Application Service</p>"},{"location":"#vmware-ops-manager-version","title":"VMware Ops Manager version","text":"<p>Splunk Firehose Nozzle has been tested on v3.0.9 LTS of VMware Ops Manager</p>"},{"location":"#usage","title":"Usage","text":"<p>Splunk nozzle is used to stream Cloud Foundry Firehose events to Splunk HTTP Event Collector. Using pre-defined Splunk sourcetypes, the nozzle automatically parses the events and enriches them with additional metadata before forwarding to Splunk. For detailed descriptions of each Firehose event type and their fields, refer to underlying dropsonde protocol. Below is a mapping of each Firehose event type to its corresponding Splunk sourcetype. Refer to Searching Events for example Splunk searches.</p> Firehose event type Splunk sourcetype Description Error <code>cf:error</code> An Error event represents an error in the originating process HttpStartStop <code>cf:httpstartstop</code> An HttpStartStop event represents the whole lifecycle of an HTTP request LogMessage <code>cf:logmessage</code> A LogMessage contains a \u201clog line\u201d and associated metadata ContainerMetric <code>cf:containermetric</code> A ContainerMetric records resource usage of an app in a container CounterEvent <code>cf:counterevent</code> A CounterEvent represents the increment of a counter ValueMetric <code>cf:valuemetric</code> A ValueMetric indicates the value of a metric at an instant in time <p>In addition, logs from the nozzle itself are of sourcetype <code>cf:splunknozzle</code>.</p>"},{"location":"#setup","title":"Setup","text":"<p>The Nozzle requires a client with the authorities <code>doppler.firehose</code> and <code>cloud_controller.admin_read_only</code> (the latter is only required if <code>ADD_APP_INFO</code> is enabled) and grant-types <code>client_credentials</code> and <code>refresh_token</code>. If <code>cloud_controller.admin_read_only</code> is not available in the system, switch to use <code>cloud_controller.admin</code>.</p> <p>You can either * Add the client manually using uaac * Add the client to the deployment manifest; see uaa.scim.users</p> <p>Manifest example:</p> <pre><code># Clients\nuaa.clients:\n    splunk-firehose:\n      id: splunk-firehose\n      override: true\n      secret: splunk-firehose-secret\n      authorized-grant-types: client_credentials,refresh_token\n      authorities: doppler.firehose,cloud_controller.admin_read_only\n</code></pre> <p><code>uaac</code> example:</p> <pre><code>uaac target https://uaa.[system domain url]\nuaac token client get admin -s [admin client credentials secret]\nuaac client add splunk-firehose --name splunk-firehose\nuaac client add splunk-firehose --secret [your_client_secret]\nuaac client add splunk-firehose --authorized_grant_types client_credentials,refresh_token\nuaac client add splunk-firehose --authorities doppler.firehose,cloud_controller.admin_read_only\n</code></pre> <p><code>cloud_controller.admin_read_only</code> will work for cf v241 or later. Earlier versions should use <code>cloud_controller.admin</code> instead.</p>"},{"location":"#environment-parameters","title":"Environment Parameters","text":"<p>You can declare parameters by making a copy of the scripts/nozzle.sh.template. * <code>DEBUG</code>: Enable debug mode (forward to standard out instead of Splunk). (Default: false).</p> <p>Cloud Foundry configuration parameters: * <code>API_ENDPOINT</code>: Cloud Foundry API endpoint address. It is required parameter. * <code>CLIENT_ID</code>: UAA Client ID (Must have authorities and grant_types described above). It is required parameter. * <code>CLIENT_SECRET</code>: Secret for Client ID. It is required parameter.</p> <p>Splunk configuration parameters: * <code>SPLUNK_TOKEN</code>: Splunk HTTP event collector token. It is required parameter. * <code>SPLUNK_HOST</code>: Splunk HTTP event collector host. example: https://example.cloud.splunk.com:8088. It is required parameter. * <code>SPLUNK_INDEX</code>: The Splunk index events will be sent to. Warning: Setting an invalid index will cause events to be lost. This index must match one of the selected indexes for the Splunk HTTP event collector token used for the SPLUNK_TOKEN parameter. It is required parameter.</p> <p>Advanced Configuration Features: * <code>JOB_NAME</code>: Tags nozzle log events with job name. It is optional. (Default: \u2018splunk-nozzle\u2019) * <code>JOB_INDEX</code>: Tags nozzle log events with job index. (Default: -1) * <code>JOB_HOST</code>: Tags nozzle log events with job host. (Default: \u201c\u201d) * <code>SKIP_SSL_VALIDATION_CF</code>: Skips SSL certificate validation for connection to Cloud Foundry. Secure communications will not check SSL certificates against a trusted certificate authority.   This is recommended for dev environments only. (Default: false) * <code>SKIP_SSL_VALIDATION_SPLUNK</code>: Skips SSL certificate validation for connection to Splunk. Secure communications will not check SSL certificates against a trusted certificate authority. (Default: false)   This is recommended for dev environments only. * <code>FIREHOSE_SUBSCRIPTION_ID</code>: Tags nozzle events with a Firehose subscription id. See https://docs.pivotal.io/pivotalcf/1-11/loggregator/log-ops-guide.html. (Default: splunk-firehose) * <code>FIREHOSE_KEEP_ALIVE</code>: Keep alive duration for the Firehose consumer. (Default: 25s) * <code>ADD_APP_INFO</code>: Enrich raw data with app info. A comma separated list of app metadata (AppName,OrgName,OrgGuid,SpaceName,SpaceGuid). (Default: \u201c\u201d) * <code>ADD_TAGS</code>: Add additional tags from envelope to splunk event. (Default: false)   (Please note: Adding tags / Enabling this feature may slightly impact the performance due to the increased event size) * <code>IGNORE_MISSING_APP</code>: If the application is missing, then stop repeatedly querying application info from Cloud Foundry. (Default: true) * <code>MISSING_APP_CACHE_INVALIDATE_TTL</code>:  How frequently the missing app info cache invalidates (in s/m/h. For example, 3600s or 60m or 1h). (Default: 0s) (see below for more details) * <code>APP_CACHE_INVALIDATE_TTL</code>: How frequently the app info local cache invalidates (in s/m/h. For example, 3600s or 60m or 1h). (Default: 0s) (see below for more details) * <code>ORG_SPACE_CACHE_INVALIDATE_TTL</code>: How frequently the org and space cache invalidates (in s/m/h. For example, 3600s or 60m or 1h). (Default: 72h) * <code>APP_LIMITS</code>: Restrict to APP_LIMITS the most updated apps per request when populating the app metadata cache. keep it 0 to update all the apps. (Default: 0) * <code>BOLTDB_PATH</code>: Bolt database path. (Default: cache.db) * <code>EVENTS</code>: A comma separated list of events to include. It is a required field. Possible values: ValueMetric,CounterEvent,Error,LogMessage,HttpStartStop,ContainerMetric. If no eventtype is selected, nozzle will automatically select LogMessage to keep the nozzle running. (Default: \u201cValueMetric,CounterEvent,ContainerMetric\u201d) * <code>EXTRA_FIELDS</code>: Extra fields to annotate your events with (format is key:value,key:value). (Default: \u201c\u201d) * <code>FLUSH_INTERVAL</code>: Time interval (in s/m/h. For example, 3600s or 60m or 1h) for flushing queue to Splunk regardless of CONSUMER_QUEUE_SIZE. Protects against stale events in low throughput systems. (Default: 5s) * <code>CONSUMER_QUEUE_SIZE</code>: Sets the internal consumer queue buffer size. Events will be pushed to Splunk after queue is full. (Default: 10000) * <code>HEC_BATCH_SIZE</code>: Set the batch size for the events to push to HEC (Splunk HTTP Event Collector). (Default: 100) * <code>HEC_RETRIES</code>: Retry count for sending events to Splunk. After expiring, events will begin dropping causing data loss. (Default: 5) * <code>HEC_WORKERS</code>: Set the amount of Splunk HEC workers to increase concurrency while ingesting in Splunk. (Default: 8) * <code>ENABLE_EVENT_TRACING</code>: Enables event trace logging. Splunk events will now contain a UUID, Splunk Nozzle Event Counts, and a Subscription-ID for Splunk correlation searches. (Default: false) * <code>SPLUNK_LOGGING_INDEX</code>: The Splunk index where logs from the nozzle of the sourcetype <code>cf:splunknozzle</code> will be sent to. Warning: Setting an invalid index will cause events to be lost. This index must match one of the selected indexes for the Splunk HTTP event collector token used for the SPLUNK_TOKEN parameter. When not provided, all logging events will be forwarded to the default SPLUNK_INDEX. The default value is <code>\"\"</code> * <code>STATUS_MONITOR_INTERVAL</code>: Time interval (in s/m/h. For example, 3600s or 60m or 1h) for Enabling Monitoring (Metric data of insights with in the connectors). Default is 0s (Disabled). * <code>SPLUNK_METRIC_INDEX</code>: Index in which metric data will be ingested when monitoring module is enabled * <code>SELECTED_MONITORING_METRICS</code>: Name of the metrics that you want to monitor and add using comma seprated values. List of the metrics that are supported in the metrics modules are given below * <code>REFRESH_SPLUNK_CONNECTION</code>: If set to true, PCF will periodically refresh connection to Splunk (how often depends on KEEP_ALIVE_TIMER value). If set to false connection will be kept alive and reused. (Default: false) * <code>KEEP_ALIVE_TIMER</code>: Time after which connection to Splunk will be refreshed, if REFRESH_SPLUNK_CONNECTION is set to true (in s/m/h. For example, 3600s or 60m or 1h). (Default: 30s)</p> <p>About app cache params:</p> <p>When ADD_APP_INFO config is enabled, the nozzle will enrich the event with app metadata. For this, the nozzle maintains a cache of all the apps locally so that it doesn\u2019t need to query from remote every time.</p> <p>Now, when there is a change in this app data in remote, the nozzle has to update this local cache. For this, the config has APP_CACHE_INVALIDATE_TTL parameter. At every APP_CACHE_INVALIDATE_TTL interval, the nozzle will update the local cache by querying the remote (CF APIs).</p> <p>If APP_CACHE_INVALIDATE_TTL is set to 10s, the nozzle will refresh the local cache at every 10s. So, AppCacheTTL should be set based on how frequently the app data is expected to change.</p> <p>When the nozzle receives events from the doppler, it will check the local cache for the given app-id. But on cache-miss, it will query remote for that specific app. If it doesn\u2019t find the app data from remote too, then the nozzle will add that app to MissingAppCache (if IGNORE_MISSING_APP config is enabled. so that the nozzle does not waste time in querying the remote for an app which is likely not to be found). So, from the next time onwards, the nozzle will first check in the MissingAppCache, if found then it will ignore the app and move on to the next event with a warning.</p> <p>MISSING_APP_CACHE_INVALIDATE_TTL is used to clear the MissingAppCache so nozzle can retry querying from remote.</p> <p>For example, given MISSING_APP_CACHE_INVALIDATE_TTL is set to 60s, when nozzle receives event from app that is not available in local cache and remote, it\u2019ll add it to MissingAppCache. Until next MISSING_APP_CACHE_INVALIDATE_TTL, nozzle will not query from remote for the missing app.</p>"},{"location":"#push-as-an-app-to-cloud-foundry","title":"Push as an App to Cloud Foundry","text":"<p>Push Splunk Firehose Nozzle as an application to Cloud Foundry. Please refer to Setup section for details on user authentication.</p> <ol> <li> <p>Download the latest release</p> <p><code>shell git clone https://github.com/cloudfoundry-community/splunk-firehose-nozzle.git cd splunk-firehose-nozzle</code></p> </li> <li> <p>Authenticate to Cloud Foundry</p> <p><code>shell cf login -a https://api.[your cf system domain] -u [your id]</code></p> </li> <li> <p>Copy the manifest template and fill in needed values (using the credentials created during setup)</p> <p><code>shell vim scripts/ci_nozzle_manifest.yml</code></p> </li> <li> <p>Push the nozzle</p> <p><code>shell make deploy-nozzle</code></p> </li> </ol>"},{"location":"#dump-application-info-to-boltdb","title":"Dump application info to boltdb","text":"<p>If in production where there are lots of CF applications (say tens of thousands) and if the user would like to enrich application logs by including application metadata, querying all application metadata information from CF may take some time - for example if we include: add app name, space ID, space name, org ID and org name to the events. If there are multiple instances of Spunk nozzle deployed the situation will be even worse, since each of the Splunk nozzle(s) will query all applications meta data and cache the metadata information to the local boltdb file. These queries will introduce load to the CF system and could potentially take a long time to finish. Users can run this tool to generate a copy of all application metadata and copy this to each Splunk nozzle deployment. Each Splunk nozzle can pick up the cache copy and update the cache file incrementally afterwards.</p> <p>Example of how to run the dump application info tool:</p> <pre><code>$ cd tools/dump_app_info\n$ go build dump_app_info.go\n$ ./dump_app_info --skip-ssl-validation --api-endpoint=https://&lt;your api endpoint&gt; --user=&lt;api endpoint login username&gt; --password=&lt;api endpoint login password&gt;\n</code></pre> <p>After populating the application info cache file, user can copy to different Splunk nozzle deployments and start Splunk nozzle to pick up this cache file by specifying correct \u201c\u2013boltdb-path\u201d flag or \u201cBOLTDB_PATH\u201d environment variable.</p>"},{"location":"#disable-logging-for-noisy-applications","title":"Disable logging for noisy applications","text":"<p>Set F2S_DISABLE_LOGGING = true as a environment variable in applications\u2019s manifest to disable logging.</p>"},{"location":"#index-routing","title":"Index routing","text":"<p>Index routing is a feature that can be used to send different Cloud Foundry logs to different indexes for better ACL and data retention control in Splunk.</p>"},{"location":"#per-application-index-routing-via-application-manifest","title":"Per application index routing via application manifest","text":"<p>To enable per app index routing, * Please set environment variable <code>SPLUNK_INDEX</code> in your application\u2019s manifest (example below) * Make sure Splunk nozzle is configured with <code>ADD_APP_INFO</code> (Select at least one of AppName,OrgName,OrgGuid,SpaceName,SpaceGuid) to enable app info caching * Make sure <code>SPLUNK_INDEX</code> specified in app\u2019s manifest exist in Splunk and can receive data for the configured Splunk HEC token.</p> <p>WARNING: If <code>SPLUNK_INDEX</code> is invalid, events from other apps may also get lost as splunk will drop entire event batch if any of the event from batch is invalid (i.e. invalid index)</p> <p>There are two ways to set the variable:</p> <p>In your app manifest provide an environment variable called <code>SPLUNK_INDEX</code> and assign it the index you would like to send the app data to.</p>"},{"location":"#example-manifest-file","title":"Example Manifest file","text":"<pre><code>applications:\n- name: &lt;App-Name&gt;\n  memory: 256M\n  disk_quota: 256M\n  ...\n  env:\n    SPLUNK_INDEX: &lt;SPLUNK_INDEX&gt;\n    ...\n</code></pre> <p>You can also update the env on the fly using cf-cli command:</p> <pre><code>cf set-env &lt;APP_NAME&gt; SPLUNK_INDEX &lt;ENV_VAR_VALUE&gt;\n</code></pre>"},{"location":"#please-note","title":"Please note","text":"<p>If you are updating env on the fly, make sure that <code>APP_CACHE_INVALIDATE_TTL</code> is greater tha 0s. Otherwise cached app-info will not be updated and events will not be sent to required index.</p>"},{"location":"#index-routing-via-splunk-configuration","title":"Index routing via Splunk configuration","text":"<p>Logs can be routed using fields such as app ID/name, space ID/name or org ID/name. Users can configure the Splunk configuration files props.conf and transforms.conf on Splunk indexers or Splunk Heavy Forwarders if deployed.</p> <p>Below are few sample configuration:</p> <p>1.  Route data from application ID <code>95930b4e-c16c-478e-8ded-5c6e9c5981f8</code> to a Splunk <code>prod</code> index:</p> <p>$SPLUNK_HOME/etc/system/local/props.conf</p> <pre><code>[cf:logmessage]\nTRANSFORMS-index_routing = route_data_to_index_by_field_cf_app_id\n</code></pre> <p>$SPLUNK_HOME/etc/system/local/transforms.conf</p> <pre><code>[route_data_to_index_by_field_cf_app_id]\nREGEX = \"(\\w+)\":\"95930b4e-c16c-478e-8ded-5c6e9c5981f8\"\nDEST_KEY = _MetaData:Index\nFORMAT = prod\n</code></pre> <p>2. Routing application logs from any Cloud Foundry orgs whose names are prefixed with <code>sales</code> to a Splunk <code>sales</code> index.</p> <p>$SPLUNK_HOME/etc/system/local/props.conf</p> <pre><code>[cf:logmessage]\nTRANSFORMS-index_routing = route_data_to_index_by_field_cf_org_name\n</code></pre> <p>$SPLUNK_HOME/etc/system/local/transforms.conf</p> <pre><code>[route_data_to_index_by_field_cf_org_name]\nREGEX = \"cf_org_name\":\"(sales.*)\"\nDEST_KEY = _MetaData:Index\nFORMAT = sales\n</code></pre> <p>3. Routing data from sourcetype <code>cf:splunknozzle</code> to index <code>new_index</code>:</p> <p>$SPLUNK_HOME/etc/system/local/props.conf</p> <pre><code>[cf:splunknozzle]\nTRANSFORMS-route_to_new_index = route_to_new_index\n</code></pre> <p>$SPLUNK_HOME/etc/system/local/transforms.conf</p> <pre><code>[route_to_new_index]\nSOURCE_KEY = MetaData:Sourcetype\nDEST_KEY =_MetaData:Index\nREGEX = (sourcetype::cf:splunknozzle)\nFORMAT = new_index\n</code></pre> <p>Note:Moving from version 1.2.4 to 1.2.5, timestamp will use nanosecond precision instead of milliseconds.</p>"},{"location":"#monitoringmetric-data-ingestion","title":"Monitoring(Metric data Ingestion):","text":"Metric Name Description <code>nozzle.queue.percentage</code> Shows how much internal queue is filled <code>splunk.events.dropped.count</code> Number of events dropped from splunk HEC <code>splunk.events.sent.count</code> Number of events sent to splunk <code>firehose.events.dropped.count</code> Number of events dropped from nozzle <code>firehose.events.received.count</code> Number of events received from firehose(websocket) <code>splunk.events.throughput</code> Average Payload size <code>nozzle.usage.ram</code> RAM Usage <code>nozzle.usage.cpu</code> CPU Usage <code>nozzle.cache.memory.hit</code> How many times it has successfully retrieved the data from memory <code>nozzle.cache.memory.miss</code> How many times it has unsuccessfully tried to retreive the data from memory <code>nozzle.cache.remote.hit</code> How many times it has successfully retrieved the data from remote <code>nozzle.cache.remote.miss</code> How many times it has unsuccessfully tried to retrieve the data from remote <code>nozzle.cache.boltdb.hit</code> How many times it has successfully retrieved the data from BoltDB <code>nozzle.cache.boltdb.miss</code> How many times it has unsuccessfully tried to retrieve the data from BoltDB <p>Note:Select value Rate(Avg) for Aggregation from Analysis tab on the top right.</p>"},{"location":"#routing-data-through-edge-processor-via-hec","title":"Routing data through edge processor via HEC","text":"<p>Logs can be routed to Splunk via Edge Processor. Assuming that you have a working Edge Processor instance, you can use it with minimal changes to nozzle configuration.</p> <p>Configuratino fields that you should change are: * <code>SPLUNK_HOST</code>: Use the host of your Edge Processor instance instead of Splunk. Example: https://x.x.x.x:8088. * <code>SPLUNK_TOKEN</code>: It is a required parameter. A token used to authorize your request, can be found in Edge Processor settings. If your   EP token authentication is turned off, you can enter a placeholder values instead (e.x. \u201c-\u201c).</p>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<p>This topic describes how to troubleshoot Splunk Firehose Nozzle for Cloud Foundry.</p>"},{"location":"#1-i-cant-find-my-data","title":"1. I can\u2019t find my data!","text":"<p>Are you searching for events and not finding them or looking at a dashboard and seeing \u201cNo result found\u201d? Check Splunk Nozzle app logs.</p> <p>To view the nozzle\u2019s logs running on CF do the following:</p> <ol> <li>Log in as an admin via the CLI.</li> <li>Target the org created by the tile. <pre>cf target -o SPLUNK-NOZZLE-ORG</pre> </li> <li>View the recent app Splunk Nozzle logs (the version number installed by the tile will vary). <pre>cf logs --recent splunk-firehoze-nozzle</pre> </li> <li>Alternatively, you can stream the app logs as they're emitted. <pre>cf logs splunk-firehose-nozzle</pre> </li> </ol>"},{"location":"#here-are-a-few-common-errors-and-possible-resolutions","title":"Here are a few common errors and possible resolutions:","text":""},{"location":"#splunk-configuration-related-errors","title":"Splunk configuration related errors:","text":"<pre>{\"timestamp\":\"\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Post http://localhost:8088/services/collector: read tcp 10.0.0.0:62931-\\u003elocalhost:8088: read: connection reset by peer\"}}\n\n<p>This error usually occurs when SSL is enabled on the Splunk HEC endpoint. Confirm that you\u2019re using https\u2019 in the Splunk HEC URL.</p>\n<pre>{\"timestamp\":\"\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Non-ok response code [400] from splunk: {\\\"text\\\":\\\"Incorrect index\\\",\\\"code\\\":7,\\\"invalid-event-number\\\":1}\"}}\n\n<p>This usually means the index value specified in the configuration doesn\u2019t exist on Splunk Host. Confirm that you\u2019re using the correct Splunk index value.</p>\n<pre>{\"timestamp\":\"\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Non-ok response code [403] from splunk: {\\\"text\\\":\\\"Invalid token\\\",\\\"code\\\":4}\"}}\n\n<p>This can occur when the Splunk HEC Token value is invalid. Confirm that you\u2019re using a valid token.</p>\n<pre>{\"timestamp\":\"\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Post https://localhost:8088/services/collector: x509: cannot validate certificate for localhost because it doesn't contain any IP SANs\"}}\n\n<p>This usually means that there was no valid SSL certificate found. Confirm that you\u2019re using a valid SSL certificate for the Splunk server, or set \u2018Skip SSL Validation\u2019 to <code>true</code> under Splunk settings.</p>\n<p>Note:Disabling SSL validation is not recommended for production environments.</p>\n\n<pre>{\"timestamp\":\"\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Post https://localhost:8088/services/collector: dial tcp localhost:8088: getsockopt: connection refused\"}}\n\n<p>This error can occur when the Splunk server is offline or when the Splunk HEC URL is not valid. Confirm that both the Splunk server is running and that you\u2019re using a valid URL.</p>"},{"location":"#cloud-foundry-configuration-related-errors","title":"Cloud Foundry configuration related errors:","text":"<pre>{\"timestamp\":\"\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Failed to run splunk-firehose-nozzle\",\"log_level\":2,\"data\":{\"error\":\"Error getting token: oauth2: cannot fetch token: 401 Unauthorized\\nResponse: {\\\"error\\\":\\\"unauthorized\\\",\\\"error_description\\\":\\\"Bad credentials\\\"}\"}}\n\n<p>This error can occur when the credentials provided for CF environment are invalid. Confirm that the API User and API Password each have access to the CF environment.</p>\n<pre>{\"timestamp\":\"\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Failed to run splunk-firehose-nozzle\",\"log_level\":2,\"data\":{\"error\":\"Could not get api /v2/info: Get https://api.cfendpoint.com/v2/info: x509: certificate signed by unknown authority\"}}\n\n<p>This means that no valid SSL certificate was found. To remediate this error, provide a valid SSL certificate for Cloud Foundry or set \u2018Skip SSL Validation\u2019 to true under Cloud Foundry Settings.</p>\n<p>Note:Disabling SSL validation is not recommended for production environments.</p>\n\n<p>The following troubleshooting tips assume you have access to Splunk to run basic searches against index <code>_internal</code> and the user-specified index for Firehose events.</p>"},{"location":"#2-ensure-splunk-nozzle-is-forwarding-events-from-the-firehose","title":"2. Ensure Splunk Nozzle is forwarding events from the Firehose:","text":"<p>Search app logs of the Nozzle to confirm correct behavior:</p>\n<pre>\nsourcetype=\"cf:splunknozzle\"\n</pre>\n\n<p>A correct setup logs a start message with configuration parameters of the Nozzle logged as a JSON object, for example:</p>\n<pre>\n  data: {\n     add-app-info: AppName,OrgName,OrgGuid,SpaceName,SpaceGuid\n     api-endpoint: https://api.endpoint.com\n     app-cache-ttl: 0\n     app-limits: 0\n     batch-size: 1000\n     boltdb-path: cache.db\n     branch: null\n     buildos: null\n     commit: null\n     debug:  false\n     extra-fields:\n     flush-interval: 5000000000\n     hec-workers: 8\n     ignore-missing-apps: true\n     job-host:\n     job-index: -1\n     job-name: splunk-nozzle\n     keep-alive: 25000000000\n     missing-app-cache-ttl:  0\n     queue-size: 10000\n     retries: 2\n     skip-ssl: true\n     splunk-host: http://localhost:8088\n     splunk-index: atomic\n     subscription-id: splunk-firehose\n     trace-logging: true\n     status-monitor-interval: 0s\n     version:\n     wanted-events: ValueMetric,CounterEvent,Error,LogMessage,HttpStartStop,ContainerMetric\n  }\n  ip: 10.0.0.0\n  log_level: 1\n  logger_source: splunk-nozzle-logger\n  message: splunk-nozzle-logger.Running splunk-firehose-nozzle with following configuration variables\n  origin: splunk_nozzle\n</pre>\n\n<p>Search app logs of the Nozzle for any errors:</p>\n<pre>\nsourcetype=\"cf:splunknozzle\" data.error=*\n</pre>\n\n<p>Errors are logged with corresponding message and stacktrace.</p>"},{"location":"#3-check-for-dropped-events-due-to-http-event-collector-availability","title":"3. Check for dropped events due to HTTP Event Collector availability:","text":"<p>As the Splunk Firehose Nozzle sends data to Splunk via HTTPS using the HTTP Event Collector, it is also susceptible to any network issues across the network path from point to point. Run the following search to determine if Splunk has indexed any events indicating issues with the HEC Endpoint.</p>\n<pre>\n  sourcetype=\"cf:splunknozzle\" \"dropping events\"\n</pre>"},{"location":"#4-check-for-dropped-events-due-to-slow-downstreamnetworksplunk","title":"4. Check for dropped events due to slow downstream(Network/Splunk):","text":"<p>If the nozzle emits the \u2018dropped events\u2019 warning saying that downstream is slow, then the network or Splunk environment might needs to be scaled. (eg. Splunk HEC receiver node, Splunk Indexer, LB etc)</p>\n<p>Run the following search to determine if Splunk has indexed any events indicating such issues.</p>\n<pre>\n  sourcetype=\"cf:splunknozzle\" \"dropped Total of\"\n</pre>"},{"location":"#5-check-for-data-loss-inside-the-splunk-firehose-nozzle","title":"5. Check for data loss inside the Splunk Firehose Nozzle:","text":"<p>If \u201cEvent Tracing\u201d is enabled, extra metadata will be attached to events. This allows searches to calculate the percentage of data loss inside the Splunk Firehose Nozzle, if applicable.</p>\n<p>Each instance of the Splunk Firehose Nozzle will run with a randomly generated UUID. The query below will display the message success rate for each UUID (Please update the index value based on your nozzle configuration).</p>\n<pre>\nindex=main | stats count as total_events, min(nozzle-event-counter) as min_number, max(nozzle-event-counter) as max_number by uuid | eval event_number =  max_number - min_number | eval success_percentage = total_events/event_number*100 | stats max(success_percentage) by uuid\n</pre>"},{"location":"#6-authentication-is-not-working-even-if-correct-cf-client-idsecret-is-configured-applicable-in-v123","title":"6. Authentication is not working even if correct CF Client ID/secret is configured: (applicable in v1.2.3)","text":"<p>Due to a known issue in an indirect dependency (an OAuth library), if the client secret has any special characters (eg. *!#$&amp;@^) then it will not work. For now, user has to configure a client secret without any of this characters. Once the library in question is updated in the next release it will work even with the special characters.</p>"},{"location":"#searching-events","title":"Searching Events","text":"<p>Here are two short Splunk queries to start exploring some of the Cloud Foundry events in Splunk.</p>\n<pre><code>sourcetype=\"cf:valuemetric\"\n    | stats avg(value) by job_instance, name\n</code></pre>\n\n<pre><code>sourcetype=\"cf:counterevent\"\n    | eval job_and_name=source+\"-\"+name\n    | stats values(job_and_name)\n</code></pre>"},{"location":"#7-nozzle-is-not-collecting-any-data-with-websocket-bad-handshake-error","title":"7. Nozzle is not collecting any data with \u2018websocket\u2019 (bad handshake) error","text":"<p>If the nozzle reports below error, then check if the configured \u201csubscription-id\u201d has \u2018#\u2019 as a prefix. Please remove the prefix or prepend any other character than \u2018#\u2019 to fix this issue.</p>\n<pre><code>Error dialing trafficcontroller server: websocket: bad handshake.\\nPlease ask your Cloud Foundry Operator to check the platform configuration (trafficcontroller is wss://****:443).\n</code></pre>"},{"location":"#development","title":"Development","text":""},{"location":"#software-requirements","title":"Software Requirements","text":"<p>Make sure you have the following installed on your workstation:</p>\n\n\n\nSoftware\nVersion\n\n\n\n\ngo\ngo1.17.x\n\n\n\n<p>Then make sure that all dependent packages are there:</p>\n<pre><code>$ cd &lt;REPO_ROOT_DIRECTORY&gt;\n$ make installdeps\n</code></pre>"},{"location":"#environment","title":"Environment","text":"<p>For development against bosh-lite,\ncopy <code>tools/nozzle.sh.template</code> to <code>tools/nozzle.sh</code> and supply missing values:</p>\n<pre><code>$ cp tools/nozzle.sh.template tools/nozzle.sh\n$ chmod +x tools/nozzle.sh\n</code></pre>\n\n<p>Build project:</p>\n<pre><code>$ make VERSION=1.3.1\n</code></pre>\n\n<p>Run tests with Ginkgo</p>\n<pre><code>$ ginkgo -r\n</code></pre>\n\n<p>Run all kinds of testing</p>\n<pre><code>$ make test # run all unittest\n$ make race # test if there is race condition in the code\n$ make vet  # examine GoLang code\n$ make cov  # code coverage test and code coverage html report\n</code></pre>\n\n<p>Or run all testings: unit test, race condition test, code coverage etc</p>\n<pre><code>$ make testall\n</code></pre>\n\n<p>Run app</p>\n<pre><code># this will run: go run main.go\n$ ./tools/nozzle.sh\n</code></pre>"},{"location":"#maintenance-and-support","title":"Maintenance And Support","text":"<p>Splunk Firehose Nozzle project is supported through Splunk Support assuming the customer has a current Splunk support entitlement.  For customers that do not have a current Splunk support entitlement, please file an issue at create a new issue</p>"},{"location":"development/","title":"Development","text":""},{"location":"development/#software-requirements","title":"Software Requirements","text":"<p>Make sure you have the following installed on your workstation:</p> Software Version go go1.17.x <p>Then make sure that all dependent packages are there:</p> <pre><code>$ cd &lt;REPO_ROOT_DIRECTORY&gt;\n$ make installdeps\n</code></pre>"},{"location":"development/#environment","title":"Environment","text":"<p>For development against bosh-lite, copy <code>tools/nozzle.sh.template</code> to <code>tools/nozzle.sh</code> and supply missing values:</p> <pre><code>$ cp tools/nozzle.sh.template tools/nozzle.sh\n$ chmod +x tools/nozzle.sh\n</code></pre> <p>Build project:</p> <pre><code>$ make VERSION=1.3.1\n</code></pre> <p>Run tests with Ginkgo</p> <pre><code>$ ginkgo -r\n</code></pre> <p>Run all kinds of testing</p> <pre><code>$ make test # run all unittest\n$ make race # test if there is race condition in the code\n$ make vet  # examine GoLang code\n$ make cov  # code coverage test and code coverage html report\n</code></pre> <p>Or run all testings: unit test, race condition test, code coverage etc</p> <pre><code>$ make testall\n</code></pre> <p>Run app</p> <pre><code># this will run: go run main.go\n$ ./tools/nozzle.sh\n</code></pre>"},{"location":"environment-variables/","title":"Environment Parameters","text":"<p>You can declare parameters by making a copy of the <code>scripts/ci_nozzle_manifest.sh</code>.</p> Variable name Description Default value <code>DEBUG</code> Enable debug mode (forward to standard out instead of Splunk) false"},{"location":"environment-variables/#cloud-foundry-configuration-parameters","title":"Cloud Foundry configuration parameters:","text":"Variable name Description Default value Mandatory parameter <code>API_ENDPOINT</code> Cloud Foundry API endpoint address - Yes <code>CLIENT_ID</code> UAA Client ID (Must have authorities and grant_types described above) - Yes <code>CLIENT_SECRET</code> Secret for Client ID. - Yes"},{"location":"environment-variables/#splunk-configuration-parameters","title":"Splunk configuration parameters:","text":"Variable name Description Default value Mandatory parameter <code>SPLUNK_TOKEN</code> Splunk HTTP event collector token - Yes <code>SPLUNK_HOST</code> Splunk HTTP event collector host, example: https://example.cloud.splunk.com:8088 - Yes <code>SPLUNK_INDEX</code> The Splunk index events will be sent to. Warning: Setting an invalid index will cause events to be lost. This index must match one of the selected indexes for the Splunk HTTP event collector token used for the <code>SPLUNK_TOKEN</code> parameter. - Yes"},{"location":"environment-variables/#advanced-configuration-features","title":"Advanced Configuration Features:","text":"Variable name Description Default value Mandatory parameter <code>JOB_NAME</code> Tags nozzle log events with job name. \u2018splunk-nozzle\u2019 No <code>JOB_INDEX</code> Tags nozzle log events with job index. -1 No <code>JOB_HOST</code> Tags nozzle log events with job host. \u201d\u201c No <code>SKIP_SSL_VALIDATION_CF</code> Skips SSL certificate validation for connection to Cloud Foundry. Secure communications will not check SSL certificates against a trusted certificate authority. This is recommended for dev environments only. false No <code>SKIP_SSL_VALIDATION_SPLUNK</code> Skips SSL certificate validation for connection to Splunk. Secure communications will not check SSL certificates against a trusted certificate authority. This is recommended for dev environments only. false No <code>FIREHOSE_SUBSCRIPTION_ID</code> Tags nozzle events with a Firehose subscription id. See here. splunk-firehose No <code>FIREHOSE_KEEP_ALIVE</code> Keep alive duration for the Firehose consumer. 25s No <code>ADD_APP_INFO</code> Enrich raw data with app info. A comma separated list of app metadata (<code>AppName,OrgName,OrgGuid,SpaceName,SpaceGuid</code>). \u201d\u201c No <code>ADD_TAGS</code> Add additional tags from envelope to splunk event. (Please note: Enabling this feature may slightly impact the performance due to the increased event size) false No <code>IGNORE_MISSING_APP</code> If the application is missing, then stop repeatedly querying application info from Cloud Foundry. true No <code>MISSING_APP_CACHE_INVALIDATE_TTL</code> How frequently the missing app info cache invalidates (in s/m/h. For example, 3600s or 60m or 1h). See about app cache params 0s No <code>APP_CACHE_INVALIDATE_TTL</code> How frequently the app info local cache invalidates (in s/m/h. For example, 3600s or 60m or 1h). See about app cache params 0s No <code>ORG_SPACE_CACHE_INVALIDATE_TTL</code> How frequently the org and space cache invalidates (in s/m/h. For example, 3600s or 60m or 1h). 72h No <code>APP_LIMITS</code> Restrict to <code>APP_LIMITS</code> the most updated apps per request when populating the app metadata cache. Keep it 0 to update all the apps. 0 No <code>BOLTDB_PATH</code> Bolt database path. cache.db No <code>EVENTS</code> A comma separated list of events to include. Possible values: ValueMetric,CounterEvent,Error,LogMessage,HttpStartStop,ContainerMetric. If no event type is selected, nozzle will automatically select LogMessage to keep the nozzle running. \u201cValueMetric,CounterEvent,ContainerMetric\u201d Yes <code>EXTRA_FIELDS</code> Extra fields to annotate your events with (format is key:value,key:value). \u201d\u201c No <code>FLUSH_INTERVAL</code> Time interval (in s/m/h. For example, 3600s or 60m or 1h) for flushing queue to Splunk regardless of <code>CONSUMER_QUEUE_SIZE</code>. Protects against stale events in low throughput systems. 5s No <code>CONSUMER_QUEUE_SIZE</code> Sets the internal consumer queue buffer size. Events will be pushed to Splunk after queue is full. 10000 No <code>HEC_BATCH_SIZE</code> Set the batch size for the events to push to HEC (Splunk HTTP Event Collector). 100 No <code>HEC_RETRIES</code> Retry count for sending events to Splunk. After expiring, events will begin dropping causing data loss. 5 No <code>HEC_WORKERS</code> Set the amount of Splunk HEC workers to increase concurrency while ingesting in Splunk. 8 No <code>ENABLE_EVENT_TRACING</code> Enables event trace logging. Splunk events will now contain a UUID, Splunk Nozzle Event Counts, and a Subscription-ID for Splunk correlation searches. false No <code>SPLUNK_LOGGING_INDEX</code> The Splunk index where logs from the nozzle of the sourcetype <code>cf:splunknozzle</code> will be sent to. Warning: Setting an invalid index will cause events to be lost. This index must match one of the selected indexes for the Splunk HTTP event collector token used for the <code>SPLUNK_TOKEN</code> parameter. When not provided, all logging events will be forwarded to the default <code>SPLUNK_INDEX</code>. \u201d\u201c No <code>STATUS_MONITOR_INTERVAL</code> Time interval (in s/m/h. For example, 3600s or 60m or 1h) to enable monitoring of metric data within the connector. (This increases CPU load and should be used only for insights purposes). 0s No <code>SPLUNK_METRIC_INDEX</code> Index in which metric data will be ingested when monitoring module is enabled - No <code>SELECTED_MONITORING_METRICS</code> Name of the metrics that you want to monitor and add using comma seprated values. List of the metrics that are supported in the metrics modules are given below - No <code>REFRESH_SPLUNK_CONNECTION</code> If set to true, PCF will periodically refresh connection to Splunk (how often depends on <code>KEEP_ALIVE_TIMER</code> value). If set to false connection will be kept alive and reused. false No <code>KEEP_ALIVE_TIMER</code> Time after which connection to Splunk will be refreshed, if <code>REFRESH_SPLUNK_CONNECTION</code> is set to true (in s/m/h. For example, 3600s or 60m or 1h). 30s No <code>MEMORY_BALLAST_SIZE</code> Size of memory allocated to reduce GC cycles. Size should be less than the total memory. 0 No"},{"location":"environment-variables/#about-app-cache-params","title":"About app cache params:","text":"<p>When <code>ADD_APP_INFO</code> config is enabled, the nozzle will enrich the event with app metadata.  For this, the nozzle maintains a cache of all the apps locally so that it does not need to query from remote every time.</p> <p>Now, when there is a change in this app data in remote, the nozzle has to update this local cache.  For this, the config has <code>APP_CACHE_INVALIDATE_TTL</code> parameter. At every <code>APP_CACHE_INVALIDATE_TTL</code> interval, the nozzle will update the local cache by querying the remote (CF APIs).</p> <p>If <code>APP_CACHE_INVALIDATE_TTL</code> is set to 10s, the nozzle will refresh the local cache at every 10s.  So, AppCacheTTL should be set based on how frequently the app data is expected to change.</p> <p>When the nozzle receives events from the doppler, it will check the local cache for the given app-id.  But on cache-miss, it will query remote for that specific app.  If it doesn\u2019t find the app data from remote too, then the nozzle will add that app to MissingAppCache  (if <code>IGNORE_MISSING_APP</code> config is enabled. so that the nozzle does not waste time in querying the remote for an app which is likely not to be found). So, from the next time onwards, the nozzle will first check in the MissingAppCache, if found then it will ignore the app and move on to the next event with a warning.</p> <p><code>MISSING_APP_CACHE_INVALIDATE_TTL</code> is used to clear the MissingAppCache so nozzle can retry querying from remote.</p> <p>For example, given <code>MISSING_APP_CACHE_INVALIDATE_TTL</code> is set to 60s, when nozzle receives event from app that is not available in local cache and remote,  it\u2019ll add it to MissingAppCache. Until next <code>MISSING_APP_CACHE_INVALIDATE_TTL</code>, nozzle will not query from remote for the missing app.</p>"},{"location":"setup/","title":"Initial setup","text":"<p>The Nozzle requires a client with the authorities <code>doppler.firehose</code> and <code>cloud_controller.admin_read_only</code> (the latter is only required if <code>ADD_APP_INFO</code> is enabled) and grant-types <code>client_credentials</code> and <code>refresh_token</code>. If <code>cloud_controller.admin_read_only</code> is not available in the system, switch to use <code>cloud_controller.admin</code>.</p> <p>You can either * Add the client manually using uaac * Add the client to the deployment manifest; see uaa.scim.users</p> <p>Manifest example:</p> <pre><code># Clients\nuaa.clients:\n    splunk-firehose:\n      id: splunk-firehose\n      override: true\n      secret: splunk-firehose-secret\n      authorized-grant-types: client_credentials,refresh_token\n      authorities: doppler.firehose,cloud_controller.admin_read_only\n</code></pre> <p><code>uaac</code> example:</p> <pre><code>uaac target https://uaa.[system domain url]\nuaac token client get admin -s [admin client credentials secret]\nuaac client add splunk-firehose --name splunk-firehose\nuaac client add splunk-firehose --secret [your_client_secret]\nuaac client add splunk-firehose --authorized_grant_types client_credentials,refresh_token\nuaac client add splunk-firehose --authorities doppler.firehose,cloud_controller.admin_read_only\n</code></pre> <p><code>cloud_controller.admin_read_only</code> will work for cf v241 or later. Earlier versions should use <code>cloud_controller.admin</code> instead.</p>"},{"location":"setup/#push-as-an-app-to-cloud-foundry","title":"Push as an App to Cloud Foundry","text":"<p>Push Splunk Firehose Nozzle as an application to Cloud Foundry. Please refer to Setup section for details on user authentication.</p> <ol> <li> <p>Download the latest release</p> <p><code>shell git clone https://github.com/cloudfoundry-community/splunk-firehose-nozzle.git cd splunk-firehose-nozzle</code></p> </li> <li> <p>Authenticate to Cloud Foundry</p> <p><code>shell cf login -a https://api.[your cf system domain] -u [your id]</code></p> </li> <li> <p>Copy the manifest template and fill in needed values (using the credentials created during setup)</p> <p><code>shell vim scripts/ci_nozzle_manifest.yml</code></p> </li> <li> <p>Push the nozzle</p> <p><code>shell make deploy-nozzle</code></p> </li> </ol>"},{"location":"setup/#dump-application-info-to-boltdb","title":"Dump application info to boltdb","text":"<p>If in production where there are lots of CF applications (say tens of thousands) and if the user would like to enrich application logs by including application metadata, querying all application metadata information from CF may take some time - for example if we include: add app name, space ID, space name, org ID and org name to the events. If there are multiple instances of Spunk nozzle deployed the situation will be even worse, since each of the Splunk nozzle(s) will query all applications meta data and cache the metadata information to the local boltdb file. These queries will introduce load to the CF system and could potentially take a long time to finish. Users can run this tool to generate a copy of all application metadata and copy this to each Splunk nozzle deployment. Each Splunk nozzle can pick up the cache copy and update the cache file incrementally afterwards.</p> <p>Example of how to run the dump application info tool:</p> <pre><code>$ cd tools/dump_app_info\n$ go build dump_app_info.go\n$ ./dump_app_info --skip-ssl-validation --api-endpoint=https://&lt;your api endpoint&gt; --user=&lt;api endpoint login username&gt; --password=&lt;api endpoint login password&gt;\n</code></pre> <p>After populating the application info cache file, user can copy to different Splunk nozzle deployments and start Splunk nozzle to pick up this cache file by specifying correct \u201c\u2013boltdb-path\u201d flag or \u201cBOLTDB_PATH\u201d environment variable.</p>"},{"location":"setup/#disable-logging-for-noisy-applications","title":"Disable logging for noisy applications","text":"<p>Set <code>F2S_DISABLE_LOGGING</code> = true as a environment variable in applications\u2019s manifest to disable logging.</p>"},{"location":"setup/#index-routing","title":"Index routing","text":"<p>Index routing is a feature that can be used to send different Cloud Foundry logs to different indexes for better ACL and data retention control in Splunk.</p>"},{"location":"setup/#per-application-index-routing-via-application-manifest","title":"Per application index routing via application manifest","text":"<p>To enable per app index routing, * Please set environment variable <code>SPLUNK_INDEX</code> in your application\u2019s manifest (example below) * Make sure Splunk nozzle is configured with <code>ADD_APP_INFO</code> (Select at least one of AppName,OrgName,OrgGuid,SpaceName,SpaceGuid) to enable app info caching * Make sure <code>SPLUNK_INDEX</code> specified in app\u2019s manifest exist in Splunk and can receive data for the configured Splunk HEC token.</p> <p>WARNING: If <code>SPLUNK_INDEX</code> is invalid, events from other apps may also get lost as splunk will drop entire event batch if any of the event from batch is invalid (i.e. invalid index)</p> <p>There are two ways to set the variable:</p> <p>In your app manifest provide an environment variable called <code>SPLUNK_INDEX</code> and assign it the index you would like to send the app data to.</p>"},{"location":"setup/#example-manifest-file","title":"Example Manifest file","text":"<pre><code>applications:\n- name: &lt;App-Name&gt;\n  memory: 256M\n  disk_quota: 256M\n  ...\n  env:\n    SPLUNK_INDEX: &lt;SPLUNK_INDEX&gt;\n    ...\n</code></pre> <p>You can also update the env on the fly using cf-cli command:</p> <pre><code>cf set-env &lt;APP_NAME&gt; SPLUNK_INDEX &lt;ENV_VAR_VALUE&gt;\n</code></pre>"},{"location":"setup/#please-note","title":"Please note","text":"<p>If you are updating env on the fly, make sure that <code>APP_CACHE_INVALIDATE_TTL</code> is greater tha 0s. Otherwise cached app-info will not be updated and events will not be sent to required index.</p>"},{"location":"setup/#index-routing-via-splunk-configuration","title":"Index routing via Splunk configuration","text":"<p>Logs can be routed using fields such as app ID/name, space ID/name or org ID/name. Users can configure the Splunk configuration files props.conf and transforms.conf on Splunk indexers or Splunk Heavy Forwarders if deployed.</p> <p>Below are few sample configuration:</p> <ol> <li>Route data from application ID <code>95930b4e-c16c-478e-8ded-5c6e9c5981f8</code> to a Splunk <code>prod</code> index:</li> </ol> <p>$SPLUNK_HOME/etc/system/local/props.conf</p> <pre><code>[cf:logmessage]\nTRANSFORMS-index_routing = route_data_to_index_by_field_cf_app_id\n</code></pre> <p>$SPLUNK_HOME/etc/system/local/transforms.conf</p> <pre><code>[route_data_to_index_by_field_cf_app_id]\nREGEX = \"(\\w+)\":\"95930b4e-c16c-478e-8ded-5c6e9c5981f8\"\nDEST_KEY = _MetaData:Index\nFORMAT = prod\n</code></pre> <ol> <li>Routing application logs from any Cloud Foundry orgs whose names are prefixed with <code>sales</code> to a Splunk <code>sales</code> index.</li> </ol> <p>$SPLUNK_HOME/etc/system/local/props.conf</p> <pre><code>[cf:logmessage]\nTRANSFORMS-index_routing = route_data_to_index_by_field_cf_org_name\n</code></pre> <p>$SPLUNK_HOME/etc/system/local/transforms.conf</p> <pre><code>[route_data_to_index_by_field_cf_org_name]\nREGEX = \"cf_org_name\":\"(sales.*)\"\nDEST_KEY = _MetaData:Index\nFORMAT = sales\n</code></pre> <ol> <li>Routing data from sourcetype <code>cf:splunknozzle</code> to index <code>new_index</code>:</li> </ol> <p>$SPLUNK_HOME/etc/system/local/props.conf</p> <pre><code>[cf:splunknozzle]\nTRANSFORMS-route_to_new_index = route_to_new_index\n</code></pre> <p>$SPLUNK_HOME/etc/system/local/transforms.conf</p> <pre><code>[route_to_new_index]\nSOURCE_KEY = MetaData:Sourcetype\nDEST_KEY =_MetaData:Index\nREGEX = (sourcetype::cf:splunknozzle)\nFORMAT = new_index\n</code></pre> <p>Note: Moving from version 1.2.4 to 1.2.5, timestamp will use nanosecond precision instead of milliseconds.</p>"},{"location":"setup/#monitoring-metric-data-ingestion","title":"Monitoring (Metric data Ingestion):","text":"Metric Name Description <code>nozzle.queue.percentage</code> Shows how much internal queue is filled <code>splunk.events.dropped.count</code> Number of events dropped from splunk HEC <code>splunk.events.sent.count</code> Number of events sent to splunk <code>firehose.events.dropped.count</code> Number of events dropped from nozzle <code>firehose.events.received.count</code> Number of events received from firehose(websocket) <code>splunk.events.throughput</code> Average Payload size <code>nozzle.usage.ram</code> RAM Usage <code>nozzle.usage.cpu</code> CPU Usage <code>nozzle.cache.memory.hit</code> How many times it has successfully retrieved the data from memory <code>nozzle.cache.memory.miss</code> How many times it has unsuccessfully tried to retreive the data from memory <code>nozzle.cache.remote.hit</code> How many times it has successfully retrieved the data from remote <code>nozzle.cache.remote.miss</code> How many times it has unsuccessfully tried to retrieve the data from remote <code>nozzle.cache.boltdb.hit</code> How many times it has successfully retrieved the data from BoltDB <code>nozzle.cache.boltdb.miss</code> How many times it has unsuccessfully tried to retrieve the data from BoltDB <p>Note: Select value Rate(Avg) for Aggregation from Analysis tab on the top right.</p> <p>You can find a pre-made dashboard that can be used for monitoring in the <code>dashboards</code> directory.</p>"},{"location":"setup/#routing-data-through-edge-processor-via-hec","title":"Routing data through edge processor via HEC","text":"<p>Logs can be routed to Splunk via Edge Processor. Assuming that you have a working Edge Processor instance, you can use it with minimal changes to nozzle configuration.</p> <p>Configuration fields that you should change are: * <code>SPLUNK_HOST</code>: Use the host of your Edge Processor instance instead of Splunk. Example: https://x.x.x.x:8088. * <code>SPLUNK_TOKEN</code>: It is a required parameter. A token used to authorize your request, can be found in Edge Processor settings. If your   EP token authentication is turned off, you can enter a placeholder values instead (e.x. \u201c-\u201c).</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This topic describes how to troubleshoot Splunk Firehose Nozzle for Cloud Foundry.</p>"},{"location":"troubleshooting/#no-data-in-splunk","title":"No data in Splunk","text":"<p>Are you searching for events and not finding them or looking at a dashboard and seeing \u201cNo result found\u201d? Check Splunk Nozzle app logs.</p> <p>To view the nozzle\u2019s logs running on CF do the following:</p> <ol> <li>Log in as an admin via the CLI.</li> <li>Target the org created by the tile.    <code>cf target -o SPLUNK-NOZZLE-ORG</code></li> <li>View the recent app Splunk Nozzle logs (the version number installed by the tile will vary).    <code>cf logs --recent splunk-firehoze-nozzle</code></li> <li>Alternatively, you can stream the app logs as they are emitted.    <code>cf logs splunk-firehose-nozzle</code></li> </ol>"},{"location":"troubleshooting/#here-are-a-few-common-errors-and-possible-resolutions","title":"Here are a few common errors and possible resolutions:","text":""},{"location":"troubleshooting/#splunk-configuration-related-errors","title":"Splunk configuration related errors:","text":"<pre><code>{\"timestamp\":\"&lt;time&gt;\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Post http://localhost:8088/services/collector: read tcp 10.0.0.0:62931-\\u003elocalhost:8088: read: connection reset by peer\"}}\n</code></pre> <p>This error usually occurs when SSL is enabled on the Splunk HEC endpoint. Confirm that you\u2019re using https\u2019 in the Splunk HEC URL.</p> <pre><code>{\"timestamp\":\"&lt;time&gt;\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Non-ok response code [400] from splunk: {\\\"text\\\":\\\"Incorrect index\\\",\\\"code\\\":7,\\\"invalid-event-number\\\":1}\"}}\n</code></pre> <p>This usually means the index value specified in the configuration doesn\u2019t exist on Splunk Host. Confirm that you\u2019re using the correct Splunk index value.</p> <pre><code>{\"timestamp\":\"&lt;time&gt;\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Non-ok response code [403] from splunk: {\\\"text\\\":\\\"Invalid token\\\",\\\"code\\\":4}\"}}\n</code></pre> <p>This can occur when the Splunk HEC Token value is invalid. Confirm that you\u2019re using a valid token.</p> <pre><code>{\"timestamp\":\"&lt;time&gt;\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Post https://localhost:8088/services/collector: x509: cannot validate certificate for localhost because it doesn't contain any IP SANs\"}}\n</code></pre> <p>This usually means that there was no valid SSL certificate found. Confirm that you\u2019re using a valid SSL certificate for the Splunk server,  or set \u2018Skip SSL Validation\u2019 to <code>true</code> under Splunk settings.</p> <p>Note: Disabling SSL validation is not recommended for production environments.</p> <pre><code>{\"timestamp\":\"&lt;time&gt;\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Unable to talk to Splunk\",\"log_level\":2,\"data\":{\"error\":\"Post https://localhost:8088/services/collector: dial tcp localhost:8088: getsockopt: connection refused\"}}\n</code></pre> <p>This error can occur when the Splunk server is offline or when the Splunk HEC URL is not valid. Confirm that both the Splunk server is running and that you\u2019re using a valid URL.</p>"},{"location":"troubleshooting/#cloud-foundry-configuration-related-errors","title":"Cloud Foundry configuration related errors:","text":"<pre><code>{\"timestamp\":\"&lt;time&gt;\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Failed to run splunk-firehose-nozzle\",\"log_level\":2,\"data\":{\"error\":\"Error getting token: oauth2: cannot fetch token: 401 Unauthorized\\nResponse: {\\\"error\\\":\\\"unauthorized\\\",\\\"error_description\\\":\\\"Bad credentials\\\"}\"}}\n</code></pre> <p>This error can occur when the credentials provided for CF environment are invalid. Confirm that the API User and API Password each have access to the CF environment.</p> <pre><code>{\"timestamp\":\"&lt;time&gt;\",\"source\":\"splunk-nozzle-logger\",\"message\":\"splunk-nozzle-logger.Failed to run splunk-firehose-nozzle\",\"log_level\":2,\"data\":{\"error\":\"Could not get api /v2/info: Get https://api.cfendpoint.com/v2/info: x509: certificate signed by unknown authority\"}}\n</code></pre> <p>This means that no valid SSL certificate was found. To remediate this error, provide a valid SSL certificate for Cloud Foundry or set  \u2018Skip SSL Validation\u2019 to true under Cloud Foundry Settings.</p> <p>Note: Disabling SSL validation is not recommended for production environments.</p> <p>The following troubleshooting tips assume you have access to Splunk to run basic searches against index <code>_internal</code> and the user-specified index for Firehose events.</p>"},{"location":"troubleshooting/#ensure-splunk-nozzle-is-forwarding-events-from-the-firehose","title":"Ensure Splunk Nozzle is forwarding events from the Firehose:","text":"<p>Search app logs of the Nozzle to confirm correct behavior:</p> <pre><code>sourcetype=\"cf:splunknozzle\"\n</code></pre> <p>A correct setup logs a start message with configuration parameters of the Nozzle logged as a JSON object, for example:</p> <pre><code>data:   \n  {\n     add-app-info: AppName,OrgName,OrgGuid,SpaceName,SpaceGuid\n     api-endpoint: https://api.endpoint.com\n     app-cache-ttl: 0\n     app-limits: 0\n     batch-size: 1000\n     boltdb-path: cache.db\n     branch: null\n     buildos: null\n     commit: null\n     debug:  false\n     extra-fields:\n     flush-interval: 5000000000\n     hec-workers: 8\n     ignore-missing-apps: true\n     job-host:\n     job-index: -1\n     job-name: splunk-nozzle\n     keep-alive: 25000000000\n     missing-app-cache-ttl:  0\n     queue-size: 10000\n     retries: 2\n     skip-ssl: true\n     splunk-host: http://localhost:8088\n     splunk-index: atomic\n     firehose-subscription-id: splunk-firehose\n     trace-logging: true\n     status-monitor-interval: 0s\n     version:\n     wanted-events: ValueMetric,CounterEvent,Error,LogMessage,HttpStartStop,ContainerMetric\n  }\n  ip: 10.0.0.0\n  log_level: 1\n  logger_source: splunk-nozzle-logger\n  message: splunk-nozzle-logger.Running splunk-firehose-nozzle with following configuration variables\n  origin: splunk_nozzle\n</code></pre> <p>Search app logs of the Nozzle for any errors:</p> <pre><code>sourcetype=\"cf:splunknozzle\" data.error=*\n</code></pre> <p>Errors are logged with corresponding message and stacktrace.</p>"},{"location":"troubleshooting/#check-for-dropped-events-due-to-http-event-collector-availability","title":"Check for dropped events due to HTTP Event Collector availability:","text":"<p>As the Splunk Firehose Nozzle sends data to Splunk via HTTPS using the HTTP Event Collector, it is also susceptible to any network issues across the network path from point to point. Run the following search to determine if Splunk has indexed any events indicating issues with the HEC Endpoint.</p> <pre><code>  sourcetype=\"cf:splunknozzle\" \"dropping events\"\n</code></pre>"},{"location":"troubleshooting/#check-for-dropped-events-due-to-slow-downstreamnetworksplunk","title":"Check for dropped events due to slow downstream(Network/Splunk):","text":"<p>If the nozzle emits the \u2018dropped events\u2019 warning saying that downstream is slow, then the network or Splunk environment might needs to be scaled. (eg. Splunk HEC receiver node, Splunk Indexer, LB etc)</p> <p>Run the following search to determine if Splunk has indexed any events indicating such issues.</p> <pre><code>  sourcetype=\"cf:splunknozzle\" \"dropped Total of\"\n</code></pre>"},{"location":"troubleshooting/#check-for-data-loss-inside-the-splunk-firehose-nozzle","title":"Check for data loss inside the Splunk Firehose Nozzle:","text":"<p>If \u201cEvent Tracing\u201d is enabled, extra metadata will be attached to events. This allows searches to calculate the percentage of data loss inside the Splunk Firehose Nozzle, if applicable.</p> <p>Each instance of the Splunk Firehose Nozzle will run with a randomly generated UUID. The query below will display the message  success rate for each UUID (Please update the index value based on your nozzle configuration).</p> <pre><code>index=main | stats count as total_events, min(nozzle-event-counter) as min_number, max(nozzle-event-counter) as max_number by uuid | eval event_number =  max_number - min_number | eval success_percentage = total_events/event_number*100 | stats max(success_percentage) by uuid\n</code></pre>"},{"location":"troubleshooting/#authentication-is-not-working-even-if-correct-cf-client-idsecret-is-configured-applicable-in-v123","title":"Authentication is not working even if correct CF Client ID/secret is configured: (applicable in v1.2.3)","text":"<p>Due to a known issue in an indirect dependency (an OAuth library), if the client secret has any special characters (eg. *!#$&amp;@^)  then it will not work. For now, user has to configure a client secret without any of this characters.  Once the library in question is updated in the next release it will work even with the special characters.</p>"},{"location":"troubleshooting/#searching-events","title":"Searching Events","text":"<p>Here are two short Splunk queries to start exploring some of the Cloud Foundry events in Splunk.</p> <pre><code>sourcetype=\"cf:valuemetric\"\n    | stats avg(value) by job_instance, name\n</code></pre> <pre><code>sourcetype=\"cf:counterevent\"\n    | eval job_and_name=source+\"-\"+name\n    | stats values(job_and_name)\n</code></pre>"},{"location":"troubleshooting/#nozzle-is-not-collecting-any-data-with-websocket-bad-handshake-error","title":"Nozzle is not collecting any data with \u2018websocket\u2019 (bad handshake) error","text":"<p>If the nozzle reports below error, then check if the configured \u201cfirehose-subscription-id\u201d has \u2018#\u2019 as a prefix.  Please remove the prefix or prepend any other character than \u2018#\u2019 to fix this issue.</p> <pre><code>Error dialing trafficcontroller server: websocket: bad handshake.\\nPlease ask your Cloud Foundry Operator to check the platform configuration (trafficcontroller is wss://****:443).\n</code></pre>"}]}